import numpy as np
def step_function(x:float)->float:
    return 1.0 if x>=0 else 0.0
def perceptron_output(wieghts,bias,x)->float:
    calculation=np.dot(wieghts,x)+bias
    return step_function(calculation)

wieghts=[2,2]
bias=-3
print(perceptron_output(wieghts,bias,[1,1]))
print(perceptron_output(wieghts,bias,[1,0]))
print(perceptron_output(wieghts,bias,[0,1]))
print(perceptron_output(wieghts,bias,[0,0]))

1.0
0.0
0.0
0.0

from typing import List
Tensor=List

def shape(tensor:Tensor)->List[int]:
    sizes:List[int]=[]
    while isinstance(tensor,List):
        sizes.append(len(tensor))
        tensor=tensor[0]
    return sizes
x=shape([1,2,3])
print(x)
x=shape([[1,2],[3,4],[5,6],[6,7]])
print(x)


[3]
[4, 2]


import numpy as np

def sigmoid(x):
    return 1 / (1 + np.exp(-x))

def neuron_output(weights, inputs):
    return sigmoid(np.dot(weights, inputs))

def feed_forward(neural_network, input_vector):
    outputs = []
    for layer in neural_network:
        input_with_bias = input_vector + [1]  # corrected typo
        output = [neuron_output(neuron, input_with_bias) for neuron in layer]
        outputs.append(output)
        input_vector = output
    return outputs

xor_network = [
    [[20, 20, -30], 
     [20, 20, -10]],
    [[-60, 60, -30]]
]

for x in [0, 1]:
    for y in [0, 1]:
        print(x, y, feed_forward(xor_network, [x, y])[-1])


0 0 [9.38314668300676e-14]
0 1 [0.9999999999999059]
1 0 [0.9999999999999059]
1 1 [9.383146683006828e-14]
